{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CoBDbSa03_d"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install git+https://github.com/huggingface/accelerate.git\n",
        "!pip install transformers datasets huggingface_hub\n",
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sjroNQ305K7",
        "outputId": "6e4f04c0-6b7a-4753-950a-63c6a5bb747e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873,
          "referenced_widgets": [
            "8007722d787244e5a5dc6e765b4d1fae",
            "e1842db76a264c079cee60b504b5169a",
            "148e0c0c26514aa598a92c37dde1d9ed",
            "973c0f2adfe44fe8886a7dc7281477cd",
            "cf4e77b840b24016a8da7ed283262457",
            "708775be15304b799bf07842c6934fb4",
            "035663a258cb4029b1c0f783842e71f8",
            "b5c05fa7b8c340db95693f40d40f13ac",
            "3a7b4857c7e54ce18152f64d4408e9f3",
            "06c2c81568be4a6cb9068237912accc6",
            "d8987ce9bc1741fb9c9bd5f57d70737a"
          ]
        },
        "id": "d1VwV5S108iT",
        "outputId": "401fbd0f-20eb-484f-d5ae-1996c8211bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8007722d787244e5a5dc6e765b4d1fae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GemmaConfig {\n",
              "  \"_name_or_path\": \"google/gemma-2b-it\",\n",
              "  \"architectures\": [\n",
              "    \"GemmaForCausalLM\"\n",
              "  ],\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 2,\n",
              "  \"eos_token_id\": 1,\n",
              "  \"head_dim\": 256,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
              "  \"hidden_size\": 2048,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 16384,\n",
              "  \"max_position_embeddings\": 8192,\n",
              "  \"model_type\": \"gemma\",\n",
              "  \"num_attention_heads\": 8,\n",
              "  \"num_hidden_layers\": 18,\n",
              "  \"num_key_value_heads\": 1,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"quantization_config\": {\n",
              "    \"_load_in_4bit\": true,\n",
              "    \"_load_in_8bit\": false,\n",
              "    \"bnb_4bit_compute_dtype\": \"float32\",\n",
              "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
              "    \"bnb_4bit_quant_type\": \"fp4\",\n",
              "    \"bnb_4bit_use_double_quant\": false,\n",
              "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
              "    \"llm_int8_has_fp16_weight\": false,\n",
              "    \"llm_int8_skip_modules\": null,\n",
              "    \"llm_int8_threshold\": 6.0,\n",
              "    \"load_in_4bit\": true,\n",
              "    \"load_in_8bit\": false,\n",
              "    \"quant_method\": \"bitsandbytes\"\n",
              "  },\n",
              "  \"rms_norm_eps\": 1e-06,\n",
              "  \"rope_scaling\": null,\n",
              "  \"rope_theta\": 10000.0,\n",
              "  \"torch_dtype\": \"bfloat16\",\n",
              "  \"transformers_version\": \"4.45.0.dev0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 256000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import time\n",
        "import torch\n",
        "import warnings\n",
        "import re\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "gemma_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-2b-it\",\n",
        "    load_in_4bit=True,\n",
        "    device_map='auto'\n",
        ")\n",
        "\n",
        "gemma_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
        "gemma_tokenizer.pad_token = gemma_tokenizer.eos_token\n",
        "\n",
        "gemma_model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvGxkANU2HQj"
      },
      "outputs": [],
      "source": [
        "def generate_response(model, tokenizer, prompt, type):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].to('cuda')\n",
        "\n",
        "    if type == \"zero_shot\":\n",
        "        max_tokens = 20\n",
        "    elif type == \"chain_of_thought\":\n",
        "        max_tokens = 200\n",
        "    elif type == \"react_prompting\":\n",
        "        max_tokens = 500\n",
        "\n",
        "    generation_config = GenerationConfig(\n",
        "      do_sample=False,\n",
        "      num_beams=1,\n",
        "      temperature=0.5,\n",
        "      repetition_penalty=1.5,\n",
        "      max_new_tokens=max_tokens\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generation_output = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=torch.ones_like(input_ids),\n",
        "            generation_config=generation_config\n",
        "        )\n",
        "\n",
        "    end_time = time.time()\n",
        "    inference_time = end_time - start_time\n",
        "\n",
        "    response = tokenizer.decode(generation_output[0], skip_special_tokens=True).strip()\n",
        "\n",
        "    return response, inference_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O7ayKep2TdS"
      },
      "outputs": [],
      "source": [
        "def zero_shot_inference(question, options):\n",
        "    prompt = f\"\"\"Please select the correct answer by responding **only** with the corresponding number (1, 2, 3, or 4) without any explanation.\n",
        "\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Options:\n",
        "    1) {options[0]}\n",
        "    2) {options[1]}\n",
        "    3) {options[2]}\n",
        "    4) {options[3]}\n",
        "\n",
        "    Answer ::\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "\n",
        "\n",
        "def chain_of_thought_inference(question, options):\n",
        "    prompt = f\"\"\"Please solve the following math problem step by step and then select the correct answer by responding **only** with the corresponding number (1, 2, 3, or 4).\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Options:\n",
        "    1) {options[0]}\n",
        "    2) {options[1]}\n",
        "    3) {options[2]}\n",
        "    4) {options[3]}\n",
        "\n",
        "    Let's break it down and solve the problem step by step. Answer :: \"\"\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy3yCnQh-EZX"
      },
      "outputs": [],
      "source": [
        "def extract_option(text):\n",
        "    pattern = r\"::[\\s\\S]*?(\\d)\"\n",
        "\n",
        "    match = re.search(pattern, text)\n",
        "\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPBcN3WJBaRQ"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"cais/mmlu\", 'college_mathematics')['test']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_count_zero_shot = 0\n",
        "correct_count_chain_of_thought = 0\n",
        "total_count = 0\n",
        "\n",
        "total_time_zero_shot = 0.0\n",
        "total_time_chain_of_thought = 0.0\n",
        "\n",
        "for example in dataset:\n",
        "    question = example['question']\n",
        "    options = example['choices']\n",
        "    correct_answer = example['answer']\n",
        "    prompt1 = zero_shot_inference(question, options)\n",
        "    prompt2 = chain_of_thought_inference(question, options)\n",
        "\n",
        "    response1, time1 = generate_response(gemma_model, gemma_tokenizer, prompt1, \"zero_shot\")\n",
        "    total_time_zero_shot += time1\n",
        "\n",
        "    response2, time2 = generate_response(gemma_model, gemma_tokenizer, prompt2, \"chain_of_thought\")\n",
        "    total_time_chain_of_thought += time2\n",
        "\n",
        "    answer1 = extract_option(response1)\n",
        "    answer2 = extract_option(response2)\n",
        "\n",
        "    if answer1 and int(answer1) == (correct_answer + 1):\n",
        "        correct_count_zero_shot += 1\n",
        "\n",
        "    if answer2 and int(answer2) == (correct_answer + 1):\n",
        "        correct_count_chain_of_thought += 1\n",
        "\n",
        "    total_count += 1\n",
        "\n",
        "accuracy_zero_shot = (correct_count_zero_shot / total_count) * 100\n",
        "accuracy_chain_of_thought = (correct_count_chain_of_thought / total_count) * 100\n",
        "\n",
        "avg_time_zero_shot = total_time_zero_shot / total_count\n",
        "avg_time_chain_of_thought = total_time_chain_of_thought / total_count\n",
        "\n",
        "print(f\"Zero-Shot Accuracy: {accuracy_zero_shot:.2f}%\")\n",
        "print(f\"Chain of Thought Accuracy: {accuracy_chain_of_thought:.2f}%\")\n",
        "\n",
        "print(f\"Average Zero-Shot Inference Time: {avg_time_zero_shot:.4f} seconds\")\n",
        "print(f\"Average Chain-of-Thought Inference Time: {avg_time_chain_of_thought:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elRs0URdobhg",
        "outputId": "48a4c9fb-0cc1-4a3b-b02a-c1d5dc281410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-Shot Accuracy: 25.81%\n",
            "Chain of Thought Accuracy: 31.18%\n",
            "Average Zero-Shot Inference Time: 1.7947 seconds\n",
            "Average Chain-of-Thought Inference Time: 17.2345 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def react_inference(question, options):\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    Example 1:\n",
        "    Question: Suppose that f(1 + x) = f(x) for all real x. If f is a polynomial and f(5) = 11, what is f(15/2)?\n",
        "\n",
        "    Thought: The equation f(1 + x) = f(x) suggests that f is periodic with a period of 1, meaning the value of f(x) repeats every 1 unit.\n",
        "    Action: Since f(5) = 11, we know f(x) = 11 for all values of x due to periodicity.\n",
        "    Observation: The value 15/2 = 7.5. By periodicity, f(7.5) = f(5) = 11.\n",
        "    Final Answer: Option 3.\n",
        "\n",
        "    Example 2:\n",
        "    Question: Let V be the set of all real polynomials p(x). Transformations T, S are defined on V by T(p(x)) -> x p(x) and S(p(x)) -> p'(x). What is true about ST(p(x))?\n",
        "\n",
        "    Thought: To evaluate ST(p(x)), first apply T and then apply S to the result.\n",
        "    Action: Apply T to p(x): T(p(x)) = x p(x). Then apply S: S(x p(x)) = p(x) + x p'(x).\n",
        "    Observation: Thus, ST(p(x)) = p(x) + x p'(x) and TS(p(x)) = x p'(x). Therefore, ST - TS = p(x), meaning ST - TS is the identity map.\n",
        "    Final Answer: Option 4\n",
        "\n",
        "\n",
        "    Now, solve this problem step by step:\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Options:\n",
        "    1) {options[0]}\n",
        "    2) {options[1]}\n",
        "    3) {options[2]}\n",
        "    4) {options[3]}\n",
        "\n",
        "    Please output the number corresponding to the correct option, Final Answer ::\n",
        "\n",
        "    Explanation :\n",
        "\n",
        "    \"\"\"\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "EiUQ8hoPctj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_count_react = 0\n",
        "total_count = 0\n",
        "total_time_react = 0\n",
        "\n",
        "for example in dataset:\n",
        "    question = example['question']\n",
        "    options = example['choices']\n",
        "    correct_answer = example['answer']\n",
        "\n",
        "    prompt3 = react_inference(question, options)\n",
        "    response3, time3 = generate_response(gemma_model, gemma_tokenizer, prompt3, \"react_prompting\")\n",
        "    total_time_react += time3\n",
        "    answer3 = extract_option(response3)\n",
        "\n",
        "    if answer3 and int(answer3) == (correct_answer + 1):\n",
        "        correct_count_react += 1\n",
        "\n",
        "    total_count += 1\n",
        "\n",
        "accuracy_react = (correct_count_react / total_count) * 100\n",
        "avg_time_react = total_time_react / total_count\n",
        "\n",
        "print(f\"ReAct Prompting Accuracy: {accuracy_react:.2f}%\")\n",
        "print(f\"Average ReAct Inference Time: {avg_time_react:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4XuhBEaZsvl",
        "outputId": "b8ce25d8-4895-4515-8c89-8e77da594c20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReAct Prompting Accuracy: 36.86%\n",
            "Average ReAct Inference Time: 41.2945 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8007722d787244e5a5dc6e765b4d1fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1842db76a264c079cee60b504b5169a",
              "IPY_MODEL_148e0c0c26514aa598a92c37dde1d9ed",
              "IPY_MODEL_973c0f2adfe44fe8886a7dc7281477cd"
            ],
            "layout": "IPY_MODEL_cf4e77b840b24016a8da7ed283262457"
          }
        },
        "e1842db76a264c079cee60b504b5169a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_708775be15304b799bf07842c6934fb4",
            "placeholder": "​",
            "style": "IPY_MODEL_035663a258cb4029b1c0f783842e71f8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "148e0c0c26514aa598a92c37dde1d9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5c05fa7b8c340db95693f40d40f13ac",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a7b4857c7e54ce18152f64d4408e9f3",
            "value": 2
          }
        },
        "973c0f2adfe44fe8886a7dc7281477cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06c2c81568be4a6cb9068237912accc6",
            "placeholder": "​",
            "style": "IPY_MODEL_d8987ce9bc1741fb9c9bd5f57d70737a",
            "value": " 2/2 [00:25&lt;00:00, 10.52s/it]"
          }
        },
        "cf4e77b840b24016a8da7ed283262457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "708775be15304b799bf07842c6934fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035663a258cb4029b1c0f783842e71f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5c05fa7b8c340db95693f40d40f13ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7b4857c7e54ce18152f64d4408e9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06c2c81568be4a6cb9068237912accc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8987ce9bc1741fb9c9bd5f57d70737a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}